{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "block_size = 16\n",
    "batch_size = 10\n",
    "max_iter = 100 * 1000\n",
    "# eval_interval = 2500\n",
    "learning_rate = 1e-4\n",
    "eval_iters = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '&', '(', ')', ',', '-', '.', '0', '1', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '—', '‘', '’', '“', '”', '\\ufeff'] \n",
      " 73\n"
     ]
    }
   ],
   "source": [
    "DIR = os.getcwd()\n",
    "filename = 'wizardofoz.txt'\n",
    "database_path = os.path.join(DIR,'data',filename)\n",
    "with open(database_path,'r',encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "chars = sorted(set(text))\n",
    "vocab_size = len(chars)\n",
    "print(chars,'\\n',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_int = { ch:i for i,ch in enumerate(chars) }\n",
    "int_to_string = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda x: [ string_to_int[c] for c in x ]\n",
    "decode = lambda x: ''.join( int_to_string[c] for c in x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([207799])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.int64)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: \n",
      "tensor([[55, 58, 45,  0, 48, 45, 58,  8,  0,  0, 34, 48, 45, 54,  1, 48],\n",
      "        [58, 52,  1, 42, 41, 60, 48, 45, 44,  1, 48, 45, 58,  1, 46, 41],\n",
      "        [45,  1, 17, 65, 43, 52, 55, 54, 45,  0,  1, 17, 48, 41, 56, 60],\n",
      "        [44,  1, 60, 48, 45,  1, 33, 43, 41, 58, 45, 43, 58, 55, 63,  1],\n",
      "        [49, 52, 52, 49, 54, 47,  1, 60, 55,  0, 55, 42, 45, 65,  1, 65],\n",
      "        [ 0, 60, 48, 45,  1, 43, 55, 61, 58, 60, 65, 41, 58, 44,  1, 60],\n",
      "        [ 1, 42, 61, 60,  6,  1, 54, 55, 63,  1, 60, 48, 41, 60,  1, 65],\n",
      "        [42, 45, 60, 63, 45, 45, 54,  1, 60, 48, 45,  1, 26, 49, 55, 54],\n",
      "        [52, 41, 54, 44,  1, 55, 46,  1, 60, 48, 45,  1, 28, 55, 58, 60],\n",
      "        [41,  1, 60, 58, 45, 53, 42, 52, 49, 54, 47,  0, 62, 55, 49, 43]],\n",
      "       device='cuda:0')\n",
      "target: \n",
      "tensor([[58, 45,  0, 48, 45, 58,  8,  0,  0, 34, 48, 45, 54,  1, 48, 45],\n",
      "        [52,  1, 42, 41, 60, 48, 45, 44,  1, 48, 45, 58,  1, 46, 41, 43],\n",
      "        [ 1, 17, 65, 43, 52, 55, 54, 45,  0,  1, 17, 48, 41, 56, 60, 45],\n",
      "        [ 1, 60, 48, 45,  1, 33, 43, 41, 58, 45, 43, 58, 55, 63,  1, 41],\n",
      "        [52, 52, 49, 54, 47,  1, 60, 55,  0, 55, 42, 45, 65,  1, 65, 55],\n",
      "        [60, 48, 45,  1, 43, 55, 61, 58, 60, 65, 41, 58, 44,  1, 60, 55],\n",
      "        [42, 61, 60,  6,  1, 54, 55, 63,  1, 60, 48, 41, 60,  1, 65, 55],\n",
      "        [45, 60, 63, 45, 45, 54,  1, 60, 48, 45,  1, 26, 49, 55, 54, 69],\n",
      "        [41, 54, 44,  1, 55, 46,  1, 60, 48, 45,  1, 28, 55, 58, 60, 48],\n",
      "        [ 1, 60, 58, 45, 53, 42, 52, 49, 54, 47,  0, 62, 55, 49, 43, 45]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.8 * data.size(dim=0))\n",
    "train_data = data[:train_size]\n",
    "val_data = data[train_size:]\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    indxs = torch.randint(data.size(dim=0) - block_size, (batch_size,))\n",
    "    x = torch.stack([ data[indx:indx+block_size] for indx in indxs ])\n",
    "    y = torch.stack([ data[indx+1:indx+block_size+1] for indx in indxs ])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "x, y = get_batch('train')\n",
    "print(\"input: \")\n",
    "print(x)\n",
    "print(\"target: \")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size,vocab_size)\n",
    "    def forward(self, index, targets=None):\n",
    "        logits = self.token_embedding_table(index)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "    def generate(self, index, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self.forward(index)\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            index_next = torch.multinomial(probs, num_samples=1)\n",
    "            index = torch.cat((index, index_next), dim=1)\n",
    "        return index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    avg_loss = dict()\n",
    "    model.eval()\n",
    "    for split in ['train','val']:\n",
    "        losses = torch.zeros((eval_iters,), dtype=torch.float16)\n",
    "        for itr in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[itr] = loss.item()\n",
    "        avg_loss[split] = losses.mean()\n",
    "    model.train()\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F9!-LbSQ?(QY‘:igv.uellU—.uHpc—det;YU UNrQWE9pdI-Wj)!!)0CeW0:wXuvSJ:Gnt1’clA’Qi!U?’”&oS?T”;;)-)NegsYQM‘YX,QIt;xO1OLfC0“uqaaQ-Iuo(YJo(bxgZpMDeTYDwY‘H.﻿NMD!TkxC’‘b“XSd-D&b,f0NtHX .uvuSJjb“X :y’OQaJfRHTddiKLXfC9’”A﻿”&aOWzd‘zaICi1HjYprd.u\n",
      " ‘HrwXuYaRiHmVGtkv-﻿sZprnJgRp\n",
      "K(,“: S.NWfAhJEOSOsLfq,(!NOy(0sOHhnK‘jKlTE”Ib-bNWj)z)lTiHp1UR;”A1!;aYK.CG&wtBCmxCcZ!;&nsq,HhY)“MY1rdOspjGR(bv\n",
      ")1oLfgF.!;UToFizD(jMDzeqgH‘DS!;wt:bxSs‘”NK‘Z’‘KiI)d.CxS9O“,Iqznt;QXfDUiSj—1‘.uLt;H-TjY-QWcSHllFGzR)E“UsO0PiziILGF OA??.kP1t,jA\n"
     ]
    }
   ],
   "source": [
    "model = BigramLanguageModel(vocab_size)\n",
    "m = model.to(device)\n",
    "\n",
    "context = torch.zeros((1,1), dtype=torch.int64, device=device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [1/100], train_loss: 4.629, val_loss: 4.621\n",
      "Step [2/100], train_loss: 4.512, val_loss: 4.508\n",
      "Step [3/100], train_loss: 4.398, val_loss: 4.402\n",
      "Step [4/100], train_loss: 4.289, val_loss: 4.285\n",
      "Step [5/100], train_loss: 4.188, val_loss: 4.176\n",
      "Step [6/100], train_loss: 4.082, val_loss: 4.078\n",
      "Step [7/100], train_loss: 3.986, val_loss: 3.977\n",
      "Step [8/100], train_loss: 3.893, val_loss: 3.885\n",
      "Step [9/100], train_loss: 3.803, val_loss: 3.795\n",
      "Step [10/100], train_loss: 3.709, val_loss: 3.705\n",
      "Step [11/100], train_loss: 3.627, val_loss: 3.621\n",
      "Step [12/100], train_loss: 3.541, val_loss: 3.539\n",
      "Step [13/100], train_loss: 3.469, val_loss: 3.467\n",
      "Step [14/100], train_loss: 3.398, val_loss: 3.396\n",
      "Step [15/100], train_loss: 3.328, val_loss: 3.328\n",
      "Step [16/100], train_loss: 3.254, val_loss: 3.264\n",
      "Step [17/100], train_loss: 3.195, val_loss: 3.197\n",
      "Step [18/100], train_loss: 3.143, val_loss: 3.141\n",
      "Step [19/100], train_loss: 3.084, val_loss: 3.084\n",
      "Step [20/100], train_loss: 3.035, val_loss: 3.029\n",
      "Step [21/100], train_loss: 2.992, val_loss: 2.988\n",
      "Step [22/100], train_loss: 2.939, val_loss: 2.941\n",
      "Step [23/100], train_loss: 2.900, val_loss: 2.902\n",
      "Step [24/100], train_loss: 2.859, val_loss: 2.859\n",
      "Step [25/100], train_loss: 2.826, val_loss: 2.822\n",
      "Step [26/100], train_loss: 2.785, val_loss: 2.791\n",
      "Step [27/100], train_loss: 2.756, val_loss: 2.762\n",
      "Step [28/100], train_loss: 2.727, val_loss: 2.734\n",
      "Step [29/100], train_loss: 2.699, val_loss: 2.703\n",
      "Step [30/100], train_loss: 2.674, val_loss: 2.684\n",
      "Step [31/100], train_loss: 2.648, val_loss: 2.646\n",
      "Step [32/100], train_loss: 2.623, val_loss: 2.625\n",
      "Step [33/100], train_loss: 2.607, val_loss: 2.615\n",
      "Step [34/100], train_loss: 2.588, val_loss: 2.592\n",
      "Step [35/100], train_loss: 2.572, val_loss: 2.574\n",
      "Step [36/100], train_loss: 2.551, val_loss: 2.557\n",
      "Step [37/100], train_loss: 2.539, val_loss: 2.547\n",
      "Step [38/100], train_loss: 2.525, val_loss: 2.531\n",
      "Step [39/100], train_loss: 2.514, val_loss: 2.520\n",
      "Step [40/100], train_loss: 2.504, val_loss: 2.510\n",
      "Step [41/100], train_loss: 2.494, val_loss: 2.500\n",
      "Step [42/100], train_loss: 2.482, val_loss: 2.486\n",
      "Step [43/100], train_loss: 2.475, val_loss: 2.484\n",
      "Step [44/100], train_loss: 2.463, val_loss: 2.471\n",
      "Step [45/100], train_loss: 2.457, val_loss: 2.465\n",
      "Step [46/100], train_loss: 2.447, val_loss: 2.455\n",
      "Step [47/100], train_loss: 2.445, val_loss: 2.449\n",
      "Step [48/100], train_loss: 2.436, val_loss: 2.441\n",
      "Step [49/100], train_loss: 2.434, val_loss: 2.441\n",
      "Step [50/100], train_loss: 2.426, val_loss: 2.439\n",
      "Step [51/100], train_loss: 2.426, val_loss: 2.426\n",
      "Step [52/100], train_loss: 2.418, val_loss: 2.428\n",
      "Step [53/100], train_loss: 2.412, val_loss: 2.418\n",
      "Step [54/100], train_loss: 2.408, val_loss: 2.418\n",
      "Step [55/100], train_loss: 2.402, val_loss: 2.416\n",
      "Step [56/100], train_loss: 2.400, val_loss: 2.410\n",
      "Step [57/100], train_loss: 2.398, val_loss: 2.410\n",
      "Step [58/100], train_loss: 2.393, val_loss: 2.404\n",
      "Step [59/100], train_loss: 2.395, val_loss: 2.400\n",
      "Step [60/100], train_loss: 2.393, val_loss: 2.402\n",
      "Step [61/100], train_loss: 2.387, val_loss: 2.398\n",
      "Step [62/100], train_loss: 2.387, val_loss: 2.398\n",
      "Step [63/100], train_loss: 2.383, val_loss: 2.396\n",
      "Step [64/100], train_loss: 2.383, val_loss: 2.391\n",
      "Step [65/100], train_loss: 2.385, val_loss: 2.389\n",
      "Step [66/100], train_loss: 2.383, val_loss: 2.387\n",
      "Step [67/100], train_loss: 2.377, val_loss: 2.385\n",
      "Step [68/100], train_loss: 2.371, val_loss: 2.381\n",
      "Step [69/100], train_loss: 2.379, val_loss: 2.381\n",
      "Step [70/100], train_loss: 2.377, val_loss: 2.381\n",
      "Step [71/100], train_loss: 2.371, val_loss: 2.377\n",
      "Step [72/100], train_loss: 2.363, val_loss: 2.379\n",
      "Step [73/100], train_loss: 2.363, val_loss: 2.373\n",
      "Step [74/100], train_loss: 2.365, val_loss: 2.377\n",
      "Step [75/100], train_loss: 2.365, val_loss: 2.373\n",
      "Step [76/100], train_loss: 2.367, val_loss: 2.373\n",
      "Step [77/100], train_loss: 2.363, val_loss: 2.373\n",
      "Step [78/100], train_loss: 2.367, val_loss: 2.369\n",
      "Step [79/100], train_loss: 2.357, val_loss: 2.377\n",
      "Step [80/100], train_loss: 2.363, val_loss: 2.373\n",
      "Step [81/100], train_loss: 2.357, val_loss: 2.367\n",
      "Step [82/100], train_loss: 2.359, val_loss: 2.361\n",
      "Step [83/100], train_loss: 2.357, val_loss: 2.371\n",
      "Step [84/100], train_loss: 2.355, val_loss: 2.369\n",
      "Step [85/100], train_loss: 2.357, val_loss: 2.365\n",
      "Step [86/100], train_loss: 2.357, val_loss: 2.361\n",
      "Step [87/100], train_loss: 2.355, val_loss: 2.367\n",
      "Step [88/100], train_loss: 2.354, val_loss: 2.369\n",
      "Step [89/100], train_loss: 2.359, val_loss: 2.369\n",
      "Step [90/100], train_loss: 2.352, val_loss: 2.361\n",
      "Step [91/100], train_loss: 2.355, val_loss: 2.363\n",
      "Step [92/100], train_loss: 2.352, val_loss: 2.359\n",
      "Step [93/100], train_loss: 2.357, val_loss: 2.363\n",
      "Step [94/100], train_loss: 2.352, val_loss: 2.361\n",
      "Step [95/100], train_loss: 2.352, val_loss: 2.359\n",
      "Step [96/100], train_loss: 2.350, val_loss: 2.359\n",
      "Step [97/100], train_loss: 2.350, val_loss: 2.363\n",
      "Step [98/100], train_loss: 2.350, val_loss: 2.361\n",
      "Step [99/100], train_loss: 2.352, val_loss: 2.359\n",
      "Step [100/100], train_loss: 2.350, val_loss: 2.357\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for i in range(max_iter):\n",
    "\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = model.forward(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (i+1) % eval_iters == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"Step [{(i+1)//eval_iters}/{max_iter//eval_iters}], train_loss: {losses['train']:.3f}, val_loss: {losses['val']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "te d, my arasum ppulle protoul can, w clol cothathon alecar. otimere soo h a kn?”\n",
      "\n",
      "jue, te are th ole thed\n",
      "g omy’st sartherinse, fithe thout I gatyoutwoins thicele rem st apou—yod brored salle avelo g t Soee—menyengr the thens te.Fit te\n",
      "Thed aseywit tt haz, ouitrd w, acor gr; plo Ozasstoofo hacey t gere andank prez,” I thead “Theyofrshy rt ingel edaringaims e may\n",
      "“Lcade lply joudiftee ve Wilid.’\n",
      "\n",
      "wo!vedd aric’julea erigitin by ure airyow dod oouan powheronowiththanere ht I.\n",
      "p as ccan t eat thy \n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1,1), dtype=torch.int64, device=device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm:gpt:v1",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
